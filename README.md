![](video/web/static/favicon/android-chrome-512x512.png)

# Media Indexer & DAM Toolbox

[![CI-Build-and-Publish](https://github.com/Cdaprod/ThatDAMToolbox/actions/workflows/ci-build-and-publish.yml/badge.svg)](https://github.com/Cdaprod/ThatDAMToolbox/actions/workflows/ci-build-and-publish.yml)

<div align="center">

<p>
  <a href="https://youtube.com/@Cdaprod">
    <img src="https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white" alt="YouTube Channel" />
  </a>
  <a href="https://twitter.com/cdasmktcda">
    <img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white" alt="Twitter Follow" />
  </a>
  <a href="https://www.linkedin.com/in/cdasmkt">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn" />
  </a>
  <a href="https://github.com/Cdaprod">
    <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub followers" />
  </a>
  <a href="https://sanity.cdaprod.dev">
    <img src="https://img.shields.io/badge/Blog-FF5722?style=for-the-badge&logo=blogger&logoColor=white" alt="Personal Blog" />
  </a>
</p>

</div>

**By David Cannan (@Cdaprod)**

> **AI-Powered Digital Asset Management System**  
> Advanced media processing, hierarchical embedding generation, and intelligent content discovery for modern video workflows.

## Overview

A comprehensive Digital Asset Management (DAM) system that combines traditional media indexing with advanced AI-powered video processing. Built for content creators, video professionals, and organizations managing large media libraries.

### System Architecture

```
Browser  â†’  FastAPI  â†’  Database
              â†˜ï¸  Worker Queue â†’ ML Workers (AI/ffmpeg)
              â†˜ï¸  /data Volume â†’ Raw Media Assets
```

## Table of Contents

- [Core Features](#core-features)
- [AI Video Processing](#ai-video-processing)
- [System Architecture](#system-architecture-details)
- [Hardware Context](#hardware-context)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [API Documentation](#api-documentation)
- [Development Roadmap](#development-roadmap)
- [Contributing](#contributing)
- [License](#license)

## Core Features

### âœ¨ AI-Powered Media Processing

- **Hierarchical Video Embeddings**: Multi-layer (L0-L3) vector representations
- **Intelligent Content Discovery**: Semantic search across video libraries
- **Automated Metadata Enrichment**: AI-generated descriptions, tags, and classifications
- **Smart Frame Extraction**: Automatic key-frame and hero-image selection

### ğŸ¬ Professional Video Workflows

- **Multi-Camera Sync**: Audio waveform analysis for perfect alignment
- **Motion Detection & Tracking**: Advanced computer vision capabilities
- **Speech-to-Text Processing**: Automated transcription with timeline sections
- **Blender Integration**: Direct pipeline to 3D workflows

### ğŸ”„ Content Management

- **Batch Processing**: Efficient handling of large media collections
- **Network Sync**: SMB/NAS integration with metadata preservation
- **Stock Platform Publishing**: Automated uploads to licensing platforms
- **iPhone Photos Integration**: Seamless HEIC/ProRes import workflows

## AI Video Processing

### Hierarchical Embedding System

The core innovation of this DAM system is its multi-level video understanding:

```mermaid
sequenceDiagram
    participant UI as Browser
    participant JS as app.js
    participant Scan as BatchScanner
    participant API as /video.server (FastAPI)
    participant DAM as /api/embedding router
    participant Store as VectorStorage

    Note over UI,JS: User drops a folder into web UI
    JS->>Scan: POST /scan?dir=/media/batch1
    Scan->>Scan: Walk dir, find foo.mp4
    Scan->>API: POST /api/embedding/videos/ingest {path:â€/media/batch1/foo.mp4â€}
    API->>DAM: forward call
    DAM->>Store: store L0 vector
    DAMâ€”>>API: {uuid:â€abcd-1234â€, levels:{L0:1}}
    APIâ€”>>Scan: 200 OK
    Note right of DAM: background task<br/>generates L1â€“L3
```

### Processing Levels

- **L0**: Raw video ingestion and basic metadata
- **L1**: Frame-level analysis and feature extraction
- **L2**: Scene segmentation and content understanding
- **L3**: Semantic relationships and cross-video connections

## System Architecture Details

### Application Stack

```mermaid
graph TD;
  CLI[â€œvideo/ (CLI)â€] â€”>|same code| API(FastAPI Service);
  API â€”>|JSON| VanillaWeb[Vanilla JS Dashboard];
  API â€”>|JSON| Streamlit[Optional Streamlit Service];
  
  subgraph Storage
    SMB[Workspace /mnt/b/] & NAS[Archive /mnt/nas/]
  end
  
  SMB & NAS â€”> HostBindMount
  HostBindMount â€”>|bind mounts| API
```

### API Endpoints

The FastAPI server provides comprehensive REST endpoints:

- `/motion/extract` - Motion Detection & Analysis
- `/scan` - File Discovery & Indexing
- `/search` - Content Search & Filtering
- `/batches` - Batch Processing Management
- `/backup` - Backup Operations
- `/sync_album` - Album Synchronization
- `/paths` - Path Management
- `/jobs` - Job Monitoring & Status

## Hardware Context

### Device Integration Matrix

The system integrates with various hardware and virtual devices for optimal performance:

```mermaid
graph RL
    subgraph â€œInput Sourcesâ€
        CAM[IP Cameras<br/>Network Sources]
        FILES[Video Files<br/>Local Storage]
        UPLOAD[Upload Sources<br/>HTTP/API]
        BACKUP[Backup Sources<br/>External Storage]
    end

    subgraph â€œNetwork Devicesâ€
        ETH[eth0 - Network Interface]
        DOCKER[docker0 - Bridge Interface]
        LO[lo - Loopback Interface]
    end

    subgraph â€œCharacter Devices (/dev/c)â€
        VIDEO0[â€œ/dev/video* - Camera Nodesâ€]
        RANDOM[â€œ/dev/random - Entropy Sourceâ€]
        NULL[â€œ/dev/null - Null Deviceâ€]
    end

    subgraph â€œBlock Devices (/dev/b)â€
        SSD[â€œ/dev/sda - Primary Storageâ€]
        BACKUP_DISK[â€œ/dev/sdb - Backup Storageâ€]
        LOOP[â€œ/dev/loop0 - Loop Deviceâ€]
    end

    subgraph â€œAPI Applicationâ€
        API[Video API Server<br/>Port 8080<br/>FastAPI/Uvicorn]
    end

    CAM â€”> ETH
    FILES â€”> SSD
    UPLOAD â€”> DOCKER
    BACKUP â€”> BACKUP_DISK
    VIDEO0 â€”> API
    ETH â€”> API
    SSD â€”> API
```

## Installation

### Prerequisites

- Python 3.8+
- Docker (recommended)
- FFmpeg
- CUDA-capable GPU (optional, for AI acceleration)

### Docker Setup (Recommended)

```bash
# Clone the repository
git clone https://github.com/Cdaprod/ThatDAMToolbox.git
cd ThatDAMToolbox

# Build and run with Docker Compose
docker-compose up -d

# Access the web interface
open http://localhost:8080
```

### Manual Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Initialize database
python -m video.db init

# Start the server
uvicorn video.server:app â€”host 0.0.0.0 â€”port 8080
```

## Quick Start

### Basic Usage

```python
from video import MediaIndexer

# Initialize the indexer
indexer = MediaIndexer()

# Scan a directory
indexer.scan(â€œ/path/to/mediaâ€)

# Get recent files
recent_media = indexer.get_recent()

# Search content
results = indexer.search(â€œsunset beachâ€)
```

### Web Interface

1. Navigate to `http://localhost:8080`
1. Drop media files or folders onto the interface
1. Monitor processing progress in real-time
1. Search and explore your indexed content

### Workflow Automation

Create JSON workflows for complex operations:

```json
{
  â€œworkflowâ€: [
    {
      â€œactionâ€: â€œsync_albumâ€,
      â€œrootâ€: â€œ/media/workspaceâ€,
      â€œalbumâ€: â€œProject Alphaâ€,
      â€œcategoryâ€: â€œeditâ€,
      â€œcopyâ€: true
    },
    { â€œactionâ€: â€œscanâ€, â€œrootâ€: â€œ/media/incomingâ€ },
    { â€œactionâ€: â€œbackupâ€, â€œbackup_rootâ€: â€œ/media/archiveâ€ },
    { â€œactionâ€: â€œstatsâ€ }
  ]
}
```

## API Documentation

### Core Endpoints

#### Scan Media Directory

```http
POST /scan?dir=/path/to/media
```

#### Ingest Video for AI Processing

```http
POST /api/embedding/videos/ingest
Content-Type: application/json

{
  â€œpathâ€: â€œ/media/video.mp4â€,
  â€œgenerate_levelsâ€: [â€œL1â€, â€œL2â€, â€œL3â€]
}
```

#### Search Content

```http
GET /search?q=sunset+beach&type=video
```

#### Get Processing Status

```http
GET /jobs/{job_id}/status
```

## Development Roadmap

### Current Progress

#### âœ… Completed

- [x] **Hierarchical Video Embedding System** - Multi-layer AI processing
- [x] **Hero + Witness Cam Tracker Export** - VFX pipeline integration
- [x] **iPhone Photos Ingestion** - HEIC/ProRes batch processing
- [x] **Stock Video Curation** - Rating and licensing workflows
- [x] **AI Batch Metadata Packaging** - XML/CSV sidecar generation
- [x] **Bulk Stock Platform Publishing** - Automated distribution

#### ğŸš§ In Progress

- [ ] **Abstract Base Models & Artifact Factory** - Domain modeling framework
- [ ] **Vanilla Frontend Browser API** - Card-based web interface
- [ ] **Network Media Sy c** - SMB/NAS/cloud integration
- [ ] **Deep Media Probe** - Advanced codec and EXIF analysis 
#### ğŸ“‹ Planned

- [ ] **Audio-Waveform Sync** - Multi-cam align ent
- [ ] **Speech-to-Text + Captions** - Advanced transcription
- [ ] **Batch Media â†’ Blender Integration** - Direct scene injection
- [ ] **Dialogue/Music Separation** - AI-powered audio processing
- [ ] **End-to-End Media Lifecycle** - Complete workflow automation

## Directory Structure

```
video/
â”œâ”€â”€ __init__.py          # Main module
â”œâ”€â”€ db.py               # Database interfxce
â”œâ”€â”€ scanner.py          # File scanning logic  
â”œâ”€â”€ sync.py             # Photo sync integration
â”œâ”€â”€ schema.sql          # Database schema
â”œâ”€â”€ web/               # Web interface
â”‚   â”œâ”€â”€ static/        # CSS, JS, assets
â”‚   â””â”€â”€ templates/     # HTML templates
â”œâ”€â”€ api/               # API modules
â”‚   â”œâ”€â”€ embedding/     # AI processing
â”‚   â””â”€â”€ motion/        # Computer vision
â””â”€â”€ workers/           # Background processors
```

## Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Fork and clone the repository
git clone https://github.com/yourusername/ThatDAMToolbox.git

# Create development environment
python -m venv venv
source venv/bin/activate

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Start development server
uvicorn video.server:app --reload
```

## License

This project is licensed under the MIT License - see the <LICENSE> file for details.

-----

<div align="center">

**Built with â¤ï¸ by [David Cannan](https://github.com/Cdaprod)**

*Transforming how we discover, process, and manage digital media through AI*

</div>